{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8839ae57-c39b-41cf-bad0-c727ed2b1b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>ProductBrand</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Price (INR)</th>\n",
       "      <th>NumImages</th>\n",
       "      <th>Description</th>\n",
       "      <th>PrimaryColor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10017413</td>\n",
       "      <td>DKNY Unisex Black &amp; Grey Printed Medium Trolle...</td>\n",
       "      <td>DKNY</td>\n",
       "      <td>Unisex</td>\n",
       "      <td>11745</td>\n",
       "      <td>7</td>\n",
       "      <td>Black and grey printed medium trolley bag, sec...</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10016283</td>\n",
       "      <td>EthnoVogue Women Beige &amp; Grey Made to Measure ...</td>\n",
       "      <td>EthnoVogue</td>\n",
       "      <td>Women</td>\n",
       "      <td>5810</td>\n",
       "      <td>7</td>\n",
       "      <td>Beige &amp; Grey made to measure kurta with churid...</td>\n",
       "      <td>Beige</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10009781</td>\n",
       "      <td>SPYKAR Women Pink Alexa Super Skinny Fit High-...</td>\n",
       "      <td>SPYKAR</td>\n",
       "      <td>Women</td>\n",
       "      <td>899</td>\n",
       "      <td>7</td>\n",
       "      <td>Pink coloured wash 5-pocket high-rise cropped ...</td>\n",
       "      <td>Pink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10015921</td>\n",
       "      <td>Raymond Men Blue Self-Design Single-Breasted B...</td>\n",
       "      <td>Raymond</td>\n",
       "      <td>Men</td>\n",
       "      <td>5599</td>\n",
       "      <td>5</td>\n",
       "      <td>Blue self-design bandhgala suitBlue self-desig...</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10017833</td>\n",
       "      <td>Parx Men Brown &amp; Off-White Slim Fit Printed Ca...</td>\n",
       "      <td>Parx</td>\n",
       "      <td>Men</td>\n",
       "      <td>759</td>\n",
       "      <td>5</td>\n",
       "      <td>Brown and off-white printed casual shirt, has ...</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID                                        ProductName ProductBrand  \\\n",
       "0   10017413  DKNY Unisex Black & Grey Printed Medium Trolle...         DKNY   \n",
       "1   10016283  EthnoVogue Women Beige & Grey Made to Measure ...   EthnoVogue   \n",
       "2   10009781  SPYKAR Women Pink Alexa Super Skinny Fit High-...       SPYKAR   \n",
       "3   10015921  Raymond Men Blue Self-Design Single-Breasted B...      Raymond   \n",
       "4   10017833  Parx Men Brown & Off-White Slim Fit Printed Ca...         Parx   \n",
       "\n",
       "   Gender  Price (INR)  NumImages  \\\n",
       "0  Unisex        11745          7   \n",
       "1   Women         5810          7   \n",
       "2   Women          899          7   \n",
       "3     Men         5599          5   \n",
       "4     Men          759          5   \n",
       "\n",
       "                                         Description PrimaryColor  \n",
       "0  Black and grey printed medium trolley bag, sec...        Black  \n",
       "1  Beige & Grey made to measure kurta with churid...        Beige  \n",
       "2  Pink coloured wash 5-pocket high-rise cropped ...         Pink  \n",
       "3  Blue self-design bandhgala suitBlue self-desig...         Blue  \n",
       "4  Brown and off-white printed casual shirt, has ...        White  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "df = pd.read_csv(\"myntra_products_catalog.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21aeab99-439e-4532-9a19-ad712a6483dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/miniconda3/lib/python3.12/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/miniconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/lib/python3.12/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/miniconda3/lib/python3.12/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.12/site-packages (from nltk) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3936dde-73e8-425f-89e2-1d33765de332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductID                                        ProductName ProductBrand  \\\n",
      "0   10017413  DKNY Unisex Black & Grey Printed Medium Trolle...         DKNY   \n",
      "1   10016283  EthnoVogue Women Beige & Grey Made to Measure ...   EthnoVogue   \n",
      "2   10009781  SPYKAR Women Pink Alexa Super Skinny Fit High-...       SPYKAR   \n",
      "3   10015921  Raymond Men Blue Self-Design Single-Breasted B...      Raymond   \n",
      "4   10017833  Parx Men Brown & Off-White Slim Fit Printed Ca...         Parx   \n",
      "\n",
      "   Gender  Price (INR)  NumImages  \\\n",
      "0  Unisex        11745          7   \n",
      "1   Women         5810          7   \n",
      "2   Women          899          7   \n",
      "3     Men         5599          5   \n",
      "4     Men          759          5   \n",
      "\n",
      "                                         Description PrimaryColor  \n",
      "0  [b, l, c, k, , n, , g, r, e, , p, r, n, e, , e...        Black  \n",
      "1  [b, e, g, e, , , , g, r, e, , e, , , e, u, r, ...        Beige  \n",
      "2  [p, n, k, , c, l, u, r, e, , w, h, , 5, , p, c...         Pink  \n",
      "3  [b, l, u, e, , e, l, f, , e, g, n, , b, n, h, ...         Blue  \n",
      "4  [b, r, w, n, , n, , f, f, , w, h, e, , p, r, n...        White  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"myntra_products_catalog.csv\")\n",
    "\n",
    "# Convert text to lowercase\n",
    "df['Description'] = df['Description'].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "# Remove special characters and punctuation\n",
    "df['Description'] = df['Description'].apply(lambda x: [re.sub(r'[^a-zA-Z0-9]', '', word) for word in x])\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['Description'] = df['Description'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['Description'] = df['Description'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Handling missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Display the preprocessed dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5783f69f-de02-49e6-9e8f-138e45c03da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.4.1.post1-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.4.1.post1-cp312-cp312-macosx_12_0_arm64.whl (10.5 MB)\n",
      "Using cached threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.4.1.post1 threadpoolctl-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93815631",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "792c127b-15fa-4fea-bfdf-25a2d4fed914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (4.39.3)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (0.22.2)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-10.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/miniconda3/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp312-cp312-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Pillow, sentence-transformers\n",
      "Successfully installed Pillow-10.3.0 sentence-transformers-2.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b71f1be4-2669-41bc-b186-673e35fe061e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.20140365 -0.19595231 -0.21754162 ... -0.04922382 -0.07640546\n",
      "   0.03788001]\n",
      " [-0.15148015  0.22381431 -0.03675901 ... -0.38603905  0.00307043\n",
      "   0.0555743 ]\n",
      " [-0.11666355 -0.04562331  0.5555767  ... -0.23504056 -0.18940534\n",
      "   0.06115248]\n",
      " ...\n",
      " [ 0.18281548  0.22342834  0.14219286 ...  0.00564762 -0.16580132\n",
      "   0.00392024]\n",
      " [-0.36495358  0.35706636 -0.0480582  ... -0.10061787  0.6028309\n",
      "  -0.25104052]\n",
      " [-0.23537362  0.43064523  0.2840123  ... -0.11608518  0.09603305\n",
      "   0.07058163]]\n",
      "[[-0.61340165  0.19605777 -0.33633378 ... -0.36248595 -0.21051712\n",
      "   0.05667027]\n",
      " [-0.18470322  0.515711    0.32999063 ... -1.1389633   0.12883532\n",
      "   0.2873996 ]\n",
      " [-0.17546363 -0.44974008  0.46660432 ... -0.7039484   0.23536463\n",
      "  -0.0317918 ]\n",
      " ...\n",
      " [ 0.0567988   0.6037305   0.6018211  ... -0.1642398   0.34838974\n",
      "  -0.08397308]\n",
      " [-0.229051    0.44784632 -0.01712654 ... -0.12007946  0.46811217\n",
      "  -0.41651493]\n",
      " [-0.47311082  0.19458875  0.42661342 ... -0.18000843  0.2688851\n",
      "   0.0984579 ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "import uuid\n",
    "\n",
    "# Load the dataset\n",
    "product_data = pd.read_csv(\"myntra_products_catalog.csv\")  # Replace \"your_dataset.csv\" with the path to your dataset\n",
    "\n",
    "# Initialize Qdrant client\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "# Create a pipeline for text preprocessing and vectorization\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer())\n",
    "])\n",
    "\n",
    "# Fit pipeline to data\n",
    "tfidf_vectors = pipeline.fit_transform(product_data['Description'].astype(str))  # Ensure the input is converted to string\n",
    "\n",
    "# Encode text data using a different language representation model (example: SentenceTransformer)\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "encoded_vectors = model.encode(product_data['Description'].astype(str))\n",
    "\n",
    "print(encoded_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b07cd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http import models\n",
    "# Check if the collection 'products' exists, if not, create i\n",
    "client=QdrantClient(host=\"localhost\",port=6333)\n",
    "my_collection=\"products\"\n",
    "client.create_collection(\n",
    "    collection_name=my_collection,\n",
    "    vectors_config=models.VectorParams(size=384,distance=models.Distance.COSINE)\n",
    ")\n",
    "  # Assuming each vector has the same dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cc5dddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Product IDs:\n",
      "7f4e5daa-6f54-4a7b-b69b-c892584f3f3c\n",
      "4bfde3fe-e4e7-40a9-8689-e621c8ce4fcd\n",
      "52d93027-08c7-4eac-8781-fc76eda9a61f\n",
      "123e6cf4-450c-4b15-9c65-d6093a1ffb2e\n",
      "ef2f3e2d-e73f-4f86-b789-4eef4ee854f7\n",
      "582e5872-ca9e-4aaa-b49a-e5c3acdeefb7\n",
      "894ab3a0-ac46-41cc-bd41-738898453d89\n",
      "4d9465b2-1ab9-46b5-9ef2-e23a0c9faa01\n",
      "d88a9835-f1d4-4e74-8588-896c0f55c50d\n",
      "ca1d66c4-5fbc-45a4-95e2-958129825df5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "import uuid\n",
    "\n",
    "# Load the dataset\n",
    "product_data = pd.read_csv(\"myntra_products_catalog.csv\")  # Replace \"your_dataset.csv\" with the path to your dataset\n",
    "\n",
    "# Initialize Qdrant client\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Store encoded vectors into Qdrant database\n",
    "def store_vectors_in_qdrant(encoded_vectors):\n",
    "    for i, vector in enumerate(encoded_vectors):\n",
    "        point_id = str(uuid.uuid4())  # Generate a unique UUID for each point\n",
    "        # Truncate the vector to contain only the first 100 elements\n",
    "        point = {\n",
    "            'id': point_id,\n",
    "            'vector': vector[:384].tolist(),\n",
    "              # Add product name attribute\n",
    "            \n",
    "        }\n",
    "        client.upsert(collection_name='products', points=[point])\n",
    "# Define function to retrieve similar products based on a query\n",
    "def recommend_similar_products(query_text, model):\n",
    "    # Encode query text\n",
    "    query_vector = model.encode([query_text])[0]\n",
    "    # Get similar products based on the query vector\n",
    "    similar_products = get_similar_products(query_vector)\n",
    "    return similar_products\n",
    "\n",
    "# Define function to get similar products from Qdrant\n",
    "def get_similar_products(query_vector):\n",
    "    # Retrieve similar products based on query vector\n",
    "    search_results = client.search(collection_name='products', query_vector=query_vector)\n",
    "    return search_results\n",
    "\n",
    "# Function to perform both storing vectors and recommending similar products\n",
    "def store_and_recommend(query_text, model):\n",
    "    store_vectors_in_qdrant(encoded_vectors)\n",
    "    similar_products = recommend_similar_products(query_text, model)\n",
    "    return similar_products\n",
    "\n",
    "# Example usage:\n",
    "query_text = input(\"Enter your query: \")\n",
    "similar_products = store_and_recommend(query_text, model)\n",
    "\n",
    "# Print recommended product IDs\n",
    "print(\"Recommended Product IDs:\")\n",
    "for product in similar_products:\n",
    "    print(product.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ac191-4aeb-4d92-be53-1e0d430ea2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3 (main, Apr  9 2024, 08:09:14) [Clang 15.0.0 (clang-1500.3.9.4)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
